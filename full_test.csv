,user,golden
gov0,"what extent people who are affected by or otherwise have an interest in an AI system have access to relevant information about the system. The Director may support measurement research and development of best practices and voluntary standards for trustworthy artificial intelligence systems, which may include model documentation, including performance metrics and constraints, measures of fairness, training and testing processes, and results… Any employer or employment agency that uses an automated employment decision tool to screen an employee or a candidate who has applied for a position for an employment decision shall notify each such employee or candidate who resides in the city that an automated employment decision tool will be used… Labeling must include instructions for use, including a detailed description of the device and compatibility information… Transparent, document, disclose, publish, label, notify, publicize, make available t009and voluntary standards for trustworthy artificial intelligence systems, including auditing mechanisms and benchmarks for accuracy, transparency, verifiability, and safety assurance for artificial intelligence systems… The AI bias evaluation shall be an impartial evaluation by an independent auditor… Audit, auditor, impartial t022 Evaluation: post-market monitoring Evaluation after the system in question begins to be sold or otherwise distributed broadly. Post-market monitoring may otherwise cover similar ground to a pre-deployment impact assessment, assessing the real-world consequences of the system, or a pre-deployment conformity assessment, assessing whether the system meets expectations. It may also assess how the system is being used in practice and by whom. [Examples in progress.] t023 Disclosure Requiring, encouraging, etc. the disclosure of information about AI systems by their users, developers, vendors, or others directly involved with the systems to third parties,","and voluntary standards for trustworthy artificial intelligence systems, including auditing mechanisms and benchmarks for accuracy, transparency, verifiability, and safety assurance for artificial intelligence systems… The AI bias evaluation shall be an impartial evaluation by an independent auditor… Audit, auditor, impartial t022 Evaluation: post-market monitoring Evaluation after the system in question begins to be sold or otherwise distributed broadly. Post-market monitoring may otherwise cover similar ground to a pre-deployment impact assessment, assessing the real-world consequences of the system, or a pre-deployment conformity assessment, assessing whether the system meets expectations. It may also assess how the system is being used in practice and by whom. [Examples in progress.] t023 Disclosure Requiring, encouraging, etc. the disclosure of information about AI systems by their users, developers, vendors, or others directly involved with the systems to third parties,group within a much larger organization. The Director of the Office of Science and Technology Policy shall establish or designate, and appoint a director of, an office to be known as the ""National Artificial Intelligence Initiative Office"" to carry out the responsibilities described in subsection (b)... The Secretary of Defense shall establish a working group on digital development infrastructure implementation to develop the plan required under subsection (a)... Office, director, secretary, working group, council, advisory council, institute, organization, department, bureau t039 Licensing, registration, and certification Requiring, incentivizing, or otherwise encouraging actors involved in AI-related activities, such as AI developers, vendors, users, or researchers, to either receive sanction from a regulator for their activities (licensing, certification) or to notify a regulator of their activity pursuant to a formal process (registration). In the case of licensing and"
gov1,"and improve performance can also increase levels of statistical uncertainty and cause issues with bias management, scientific validity, and reproducibility. • Higher degree of difficulty in predicting failure modes for emergent properties of large-scale pre-trained models. • Privacy risk due to enhanced data aggregation capability for AI systems. • AI systems may require more frequent maintenance and triggers for conducting cor- rective maintenance due to data, model, or concept drift. • Increased opacity and concerns about reproducibility. • Underdeveloped software testing standards and inability to document AI-based prac- tices to the standard expected of traditionally engineered software for all but the simplest of cases. • Difficulty in performing regular AI-based software testing, or determining what to test, since AI systems are not subject to the same controls as traditional code devel- opment. Page 38---- Page 24 ---- NIST AI 100-1 AI RMF 1.0 Part 2: Core and Profiles 5. AI RMF Core The AI RMF Core provides outcomes and actions that enable dialogue, understanding, and activities to manage AI risks and responsibly develop trustworthy AI systems. As illus- trated in Figure 5, the Core is composed of four functions: GOVERN ,MAP ,MEASURE , and MANAGE . Each of these high-level functions is broken down into categories and sub- categories. Categories and subcategories are subdivided into specific actions and outcomes. Actions do not constitute a checklist, nor are they necessarily an ordered set of steps. Fig. 5. Functions organize AI risk management activities at their highest level to govern, map, measure, and manage AI risks. Governance is designed to be a cross-cutting function to inform and be infused throughout the other three functions. Risk management should be continuous, timely, and performed throughout the AI system lifecycle dimensions. AI RMF Core functions should be carried","Issues that merit further consideration and research include: 1.Human roles and responsibilities in decision making and overseeing AI systems need to be clearly defined and differentiated. Human-AI configurations can span from fully autonomous to fully manual. AI systems can autonomously make deci- sions, defer decision making to a human expert, or be used by a human decision maker as an additional opinion. Some AI systems may not require human oversight, such as models used to improve video compression. Other systems may specifically require human oversight. 2.Decisions that go into the design, development, deployment, evaluation, and use of AI systems reflect systemic and human cognitive biases. AI actors bring their cognitive biases, both individual and group, into the process. Biases can stem from end-user decision-making tasks and be introduced across the AI lifecycle via human assumptions, expectations, and decisions during design and modeling tasks. These biases, which are notand operations. Documentation can enhance transparency, improve human review processes, and bolster accountability in AI system teams. After putting in place the structures, systems, processes, and teams described in the GOV- ERN function, organizations should benefit from a purpose-driven culture focused on risk understanding and management. It is incumbent on Framework users to continue to ex- ecute the GOVERN function as knowledge, cultures, and needs or expectations from AI actors evolve over time. Practices related to governing AI risks are described in the NIST AI RMF Playbook. Table 1 lists the GOVERN function’s categories and subcategories. Table 1: Categories and subcategories for the GOVERN function. GOVERN 1: Policies, processes, procedures, and practices across the organization related to the mapping, measuring, and managing of AI risks are in place, transparent, and implemented effectively.GOVERN 1.1: Legal and regulatory requirements involving AI are understood, managed,"
map0,"authorizing, encouraging, or allocating resources for AI-related studies, reports, or plans to be prepared by or for the government. …the Task Force shall submit to Congress and the President an interim report containing the findings, conclusions, and recommendations of the Task Force… The Interagency Committee shall…not later than 2 years after January 1, 2021, develop a strategic plan for artificial intelligence (to be updated not less than every 3 years) that establishes goals, priorities, and metrics for guiding and evaluating… …the Secretary of Defense shall review the potential applications of artificial intelligence and digital technology to the platforms, processes, and operations of the Department of Defense… Report, study, analysis, plan, strategy, framework, review, assessment t031 Government support Authorizing, planning for, allocating resources for, defining eligibility for, creating or revising procedures for, or otherwise managing government support for AI-relatedFor this batch, you will tag documents with the domains of AI application they explicitly address. Basically, think: “what kinds of real-world AI is this about?”","For this batch, you will tag documents with the types of AI-related harms it addresses. Basically, think: what real-world consequences of the development or use of AI is this document meant to prevent?For this batch, you will tag documents with the domains of AI application they explicitly address. Basically, think: “what kinds of real-world AI is this about?”"
map1,"such as predictions, recommenda- tions, or decisions influencing real or virtual environments. AI systems are designed to operate with varying levels of autonomy (Adapted from: OECD Recommendation on AI:2019; ISO/IEC22989:2022). While there are myriad standards and best practices to help organizations mitigate the risks of traditional software or information-based systems, the risks posed by AI systems are in many ways unique (See Appendix B). AI systems, for example, may be trained on data that can change over time, sometimes significantly and unexpectedly, affecting system function- ality and trustworthiness in ways that are hard to understand. AI systems and the contexts in which they are deployed are frequently complex, making it difficult to detect and respond to failures when they occur. AI systems are inherently socio-technical in nature, meaning they are influenced by societal dynamics and human behavior. AI risks – and benefits – can emerge from the interplay of technicaldeployment, and use of AI systems over time. AI actors are defined by the Organisation for Economic Co-operation and Development (OECD) as “those who play an active role in the AI system lifecycle, including organiza- tions and individuals that deploy or operate AI” [OECD (2019) Artificial Intelligence in Society—OECD iLibrary] (See Appendix A). The AI RMF is intended to be practical, to adapt to the AI landscape as AI technologies continue to develop, and to be operationalized by organizations in varying degrees and capacities so society can benefit from AI while also being protected from its potential harms. The Framework and supporting resources will be updated, expanded, and improved based on evolving technology, the standards landscape around the world, and AI community ex- perience and feedback. NIST will continue to align the AI RMF and related guidance with applicable international standards, guidelines, and practices. As the AI RMF is put into use, additional lessons will be","(e.g., UX/UI design), governance experts, data engineers, data providers, system funders, product man- agers, third-party entities, evaluators, and legal and privacy governance. AI Development tasks are performed during the AI Model phase of the lifecycle in Figure 2. AI Development actors provide the initial infrastructure of AI systems and are responsi- ble for model building and interpretation tasks, which involve the creation, selection, cali- bration, training, and/or testing of models or algorithms. AI actors in this category include machine learning experts, data scientists, developers, third-party entities, legal and privacy governance experts, and experts in the socio-cultural and contextual factors associated with the deployment setting. AI Deployment tasks are performed during the Task and Output phase of the lifecycle in Figure 2. AI Deployment actors are responsible for contextual decisions relating to how the AI system is used to assure deployment of the system intowith financial, legal, or policy management authority for acquisition of AI models, products, or services from a third-party developer, vendor, or contractor. Governance and Oversight tasks are assumed by AI actors with management, fiduciary, and legal authority and responsibility for the organization in which an AI system is de- Page 36"
mea0,"and voluntary standards for trustworthy artificial intelligence systems, including auditing mechanisms and benchmarks for accuracy, transparency, verifiability, and safety assurance for artificial intelligence systems… The AI bias evaluation shall be an impartial evaluation by an independent auditor… Audit, auditor, impartial t022 Evaluation: post-market monitoring Evaluation after the system in question begins to be sold or otherwise distributed broadly. Post-market monitoring may otherwise cover similar ground to a pre-deployment impact assessment, assessing the real-world consequences of the system, or a pre-deployment conformity assessment, assessing whether the system meets expectations. It may also assess how the system is being used in practice and by whom. [Examples in progress.] t023 Disclosure Requiring, encouraging, etc. the disclosure of information about AI systems by their users, developers, vendors, or others directly involved with the systems to third parties,including safety and robustness, including assurance, verification, validation, security, and control. The Director may support measurement research and development of best practices and voluntary standards for trustworthy artificial intelligence systems, which may include safety and robustness of artificial intelligence systems, including assurance, verification, validation, security, control, and the ability for artificial intelligence systems to withstand unexpected inputs and adversarial attacks… Robust, reliable, perturbation, unexpected, out of distribution, adversarial input, adversarial example t003 Interpretability and explainability The document governs whether humans can understand (a) the mechanisms underlying an AI system’s operation and/or (b) the meaning of the systems’ output in the context of use. The Secretary shall fund research into the development of trustworthy artificial intelligence systems, including algorithmic explainability. Interpretable, explainable,","use, including detection of gastrointestinal lesions… Audit, assessment, assess, impact assessment, red team, test, evaluate, metric, measure, monitor t018 Evaluation: adversarial testing Evaluation in which the evaluator takes an adversarial approach, seeking to subvert or otherwise produce undesirable results from the system or process being tested by any means available. Sometimes called ""red teaming."" [Examples in progress.] Red team, penetration test, security audit t019 Evaluation: impact assessment An impact assessment involves systematically predicting the real-world consequences of an AI system before it is deployed. It may or may not also involve: Measuring the potential consequences Mitigating, or articulating ways to mitigate, the potential consequences Justifying the potential consequences Assessing how the consequences may affect particular entities, such as groups, assets, activities, or institutions Documenting any of the foregoing steps or their outputs Publicizingactivities, or institutions Documenting any of the foregoing steps or their outputs Publicizing any of the foregoing steps or their outputs Soliciting, collecting, considering, and/or acting on public input related to any of the foregoing steps or their outputs [Examples in progress.] [Examples in progress.] t020 Evaluation: conformity assessment Evaluation of whether a deployed AI system meets the expectations specified or claimed prior to deployment. Clinical performance testing must demonstrate that the device performs as intended… [Examples in progress.] t021 Evaluation: external auditing Evaluation by a disinterested counterparty or third party, such as a customer or a professional auditing firm. Any type of evaluation meeting the definition of ""Evaluation"" specified above may be implemented as auditing. The Director may support measurement research and development of best practices and voluntary standards for trustworthy artificial intelligence systems, including auditing"
mea1,"the AI lifecycle can en- hance opportunities for informing contextually sensitive evaluations, and for identifying AI system benefits and positive impacts. These practices can increase the likelihood that risks arising in social contexts are managed appropriately. Understanding and treatment of trustworthiness characteristics depends on an AI actor’s particular role within the AI lifecycle. For any given AI system, an AI designer or developer may have a different perception of the characteristics than the deployer. Trustworthiness characteristics explained in this document influence each other. Highly secure but unfair systems, accurate but opaque and uninterpretable systems, and inaccurate but secure, privacy-enhanced, and transparent systems are all unde- sirable. A comprehensive approach to risk management calls for balancing tradeoffs among the trustworthiness characteristics. It is the joint responsibility of all AI ac- tors to determine whether AI technology is an appropriate ormethods such as de-identification and aggregation for certain model outputs, can support design for privacy-enhanced AI systems. Under certain conditions such as data sparsity, privacy- enhancing techniques can result in a loss in accuracy, affecting decisions about fairness and other values in certain domains. 3.7 Fair – with Harmful Bias Managed Fairness in AI includes concerns for equality and equity by addressing issues such as harm- ful bias and discrimination. Standards of fairness can be complex and difficult to define be- cause perceptions of fairness differ among cultures and may shift depending on application. Organizations’ risk management efforts will be enhanced by recognizing and considering these differences. Systems in which harmful biases are mitigated are not necessarily fair. For example, systems in which predictions are somewhat balanced across demographic groups may still be inaccessible to individuals with disabilities or affected by the digital divide or may","experience, perform human-centered evaluation and testing, and inform impact assessments. Domain Expert tasks involve input from multidisciplinary practitioners or scholars who provide knowledge or expertise in – and about – an industry sector, economic sector, con- text, or application area where an AI system is being used. AI actors who are domain experts can provide essential guidance for AI system design and development, and inter- pret outputs in support of work performed by TEVV and AI impact assessment teams. AI Impact Assessment tasks include assessing and evaluating requirements for AI system accountability, combating harmful bias, examining impacts of AI systems, product safety, liability, and security, among others. AI actors such as impact assessors and evaluators provide technical, human factor, socio-cultural, and legal expertise. Procurement tasks are conducted by AI actors with financial, legal, or policy management authority for acquisition of AI models, products, or---- Page 10 ---- NIST AI 100-1 AI RMF 1.0 AI system impact assessment approaches can help AI actors understand potential impacts or harms within specific contexts. Availability of reliable metrics: The current lack of consensus on robust and verifiable measurement methods for risk and trustworthiness, and applicability to different AI use cases, is an AI risk measurement challenge. Potential pitfalls when seeking to measure negative risk or harms include the reality that development of metrics is often an institu- tional endeavor and may inadvertently reflect factors unrelated to the underlying impact. In addition, measurement approaches can be oversimplified, gamed, lack critical nuance, be- come relied upon in unexpected ways, or fail to account for differences in affected groups and contexts. Approaches for measuring impacts on a population work best if they recognize that contexts matter, that harms may affect varied groups or sub-groups differently, and that communities or other"
man0,"authorizing, encouraging, or allocating resources for AI-related studies, reports, or plans to be prepared by or for the government. …the Task Force shall submit to Congress and the President an interim report containing the findings, conclusions, and recommendations of the Task Force… The Interagency Committee shall…not later than 2 years after January 1, 2021, develop a strategic plan for artificial intelligence (to be updated not less than every 3 years) that establishes goals, priorities, and metrics for guiding and evaluating… …the Secretary of Defense shall review the potential applications of artificial intelligence and digital technology to the platforms, processes, and operations of the Department of Defense… Report, study, analysis, plan, strategy, framework, review, assessment t031 Government support Authorizing, planning for, allocating resources for, defining eligibility for, creating or revising procedures for, or otherwise managing government support for AI-relatedincluding safety and robustness, including assurance, verification, validation, security, and control. The Director may support measurement research and development of best practices and voluntary standards for trustworthy artificial intelligence systems, which may include safety and robustness of artificial intelligence systems, including assurance, verification, validation, security, control, and the ability for artificial intelligence systems to withstand unexpected inputs and adversarial attacks… Robust, reliable, perturbation, unexpected, out of distribution, adversarial input, adversarial example t003 Interpretability and explainability The document governs whether humans can understand (a) the mechanisms underlying an AI system’s operation and/or (b) the meaning of the systems’ output in the context of use. The Secretary shall fund research into the development of trustworthy artificial intelligence systems, including algorithmic explainability. Interpretable, explainable,","what extent people who are affected by or otherwise have an interest in an AI system have access to relevant information about the system. The Director may support measurement research and development of best practices and voluntary standards for trustworthy artificial intelligence systems, which may include model documentation, including performance metrics and constraints, measures of fairness, training and testing processes, and results… Any employer or employment agency that uses an automated employment decision tool to screen an employee or a candidate who has applied for a position for an employment decision shall notify each such employee or candidate who resides in the city that an automated employment decision tool will be used… Labeling must include instructions for use, including a detailed description of the device and compatibility information… Transparent, document, disclose, publish, label, notify, publicize, make available t009and voluntary standards for trustworthy artificial intelligence systems, including auditing mechanisms and benchmarks for accuracy, transparency, verifiability, and safety assurance for artificial intelligence systems… The AI bias evaluation shall be an impartial evaluation by an independent auditor… Audit, auditor, impartial t022 Evaluation: post-market monitoring Evaluation after the system in question begins to be sold or otherwise distributed broadly. Post-market monitoring may otherwise cover similar ground to a pre-deployment impact assessment, assessing the real-world consequences of the system, or a pre-deployment conformity assessment, assessing whether the system meets expectations. It may also assess how the system is being used in practice and by whom. [Examples in progress.] t023 Disclosure Requiring, encouraging, etc. the disclosure of information about AI systems by their users, developers, vendors, or others directly involved with the systems to third parties,"
man1,"such as predictions, recommenda- tions, or decisions influencing real or virtual environments. AI systems are designed to operate with varying levels of autonomy (Adapted from: OECD Recommendation on AI:2019; ISO/IEC22989:2022). While there are myriad standards and best practices to help organizations mitigate the risks of traditional software or information-based systems, the risks posed by AI systems are in many ways unique (See Appendix B). AI systems, for example, may be trained on data that can change over time, sometimes significantly and unexpectedly, affecting system function- ality and trustworthiness in ways that are hard to understand. AI systems and the contexts in which they are deployed are frequently complex, making it difficult to detect and respond to failures when they occur. AI systems are inherently socio-technical in nature, meaning they are influenced by societal dynamics and human behavior. AI risks – and benefits – can emerge from the interplay of technical---- Page 28 ---- NIST AI 100-1 AI RMF 1.0 Table 1: Categories and subcategories for the GOVERN function. (Continued) that considers and communicates AI risk.GOVERN 4.2: Organizational teams document the risks and po- tential impacts of the AI technology they design, develop, deploy, evaluate, and use, and they communicate about the impacts more broadly. GOVERN 4.3: Organizational practices are in place to enable AI testing, identification of incidents, and information sharing. GOVERN 5: Processes are in place for robust engagement with relevant AI actors.GOVERN 5.1: Organizational policies and practices are in place to collect, consider, prioritize, and integrate feedback from those external to the team that developed or deployed the AI system regarding the potential individual and societal impacts related to AI risks. GOVERN 5.2: Mechanisms are established to enable the team that developed or deployed AI systems to regularly incorporate adjudicated feedback from relevant AI actors","such as predictions, recommenda- tions, or decisions influencing real or virtual environments. AI systems are designed to operate with varying levels of autonomy (Adapted from: OECD Recommendation on AI:2019; ISO/IEC22989:2022). While there are myriad standards and best practices to help organizations mitigate the risks of traditional software or information-based systems, the risks posed by AI systems are in many ways unique (See Appendix B). AI systems, for example, may be trained on data that can change over time, sometimes significantly and unexpectedly, affecting system function- ality and trustworthiness in ways that are hard to understand. AI systems and the contexts in which they are deployed are frequently complex, making it difficult to detect and respond to failures when they occur. AI systems are inherently socio-technical in nature, meaning they are influenced by societal dynamics and human behavior. AI risks – and benefits – can emerge from the interplay of technicalcontextual decisions relating to how the AI system is used to assure deployment of the system into production. Related tasks include piloting the system, checking compatibility with legacy systems, ensuring regu- latory compliance, managing organizational change, and evaluating user experience. AI actors in this category include system integrators, software developers, end users, oper- ators and practitioners, evaluators, and domain experts with expertise in human factors, socio-cultural analysis, and governance. Operation and Monitoring tasks are performed in the Application Context/Operate and Monitor phase of the lifecycle in Figure 2. These tasks are carried out by AI actors who are responsible for operating the AI system and working with others to regularly assess system output and impacts. AI actors in this category include system operators, domain experts, AI designers, users who interpret or incorporate the output of AI systems, product developers, evaluators and auditors,"
